{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjubes/DataMining/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "ChJjT8mSegwr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "import pandas as pd\n",
        "import random\n",
        "from collections import Counter\n",
        "from scipy import stats\n",
        "\n",
        "class DecisionNode():\n",
        "    def __init__(self, feature=None, splitpoint=None, left=None, right=None, value=None, leaf=False):\n",
        "      self.feature = feature          # Feature to split on, column index\n",
        "      self.splitpoint = splitpoint    # Threshold value for the split\n",
        "      self.left = left                # Left subtree\n",
        "      self.right = right              # Right subtree\n",
        "      self.value = value              # If leaf node, the predicted class\n",
        "      self.leaf = leaf                # If node is leaf node\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "      return self.leaf\n",
        "\n",
        "def impurity(a):\n",
        "  i = (np.count_nonzero(a == 0)/len(a))*(1-np.count_nonzero(a == 0)/len(a))\n",
        "  return i\n",
        "\n",
        "def bestsplit(x,y, minleaf):\n",
        "# this function is for a single feature\n",
        "#return best splitpoint, reduction of splitpoint (gini index)\n",
        "\n",
        "  #The best split is the split that achieves the highest impurity reduction.\n",
        "  impurity_parent = impurity(y)\n",
        "\n",
        "  x_sorted = np.sort(np.unique(x))\n",
        "  x_splitpoints = (x_sorted[0:(len(x_sorted)-1)]+x_sorted[1:(len(x_sorted))])/2\n",
        "\n",
        "  reductions = []\n",
        "  for s in x_splitpoints:\n",
        "    #go over all the splitpoints\n",
        "    left = impurity(y[x <= s])\n",
        "    l = len(y[x <= s])/len(y)\n",
        "    right = impurity(y[x > s])\n",
        "    r = len(y[x > s])/len(y)\n",
        "\n",
        "    #calculate gini reduction\n",
        "    reduction = impurity_parent - ((l*left) + r*(right))\n",
        "\n",
        "    #only if minleaf parameter is correct\n",
        "    if (len(y[x<=s]) >= minleaf) and (len(y[x>s]) >= minleaf):\n",
        "      reductions.append(reduction)\n",
        "\n",
        "  # the reductions list is empty if the minleaf constraint is not satisfied\n",
        "  if reductions == []:\n",
        "    return None, 0\n",
        "\n",
        "  best_splitpoint = x_splitpoints[reductions.index(max(reductions))]\n",
        "\n",
        "  return best_splitpoint, max(reductions)\n",
        "\n",
        "def split(x,y,minleaf,nfeat):\n",
        "  #this function finds which feature has the best split, using the best_split function\n",
        "  # which feature do we split on, and what is the threshold?\n",
        "  best_reduction = 0\n",
        "  best_splitpoint = None\n",
        "  column_i = None\n",
        "  i = 0\n",
        "  n_features = len(x.T)\n",
        "\n",
        "  #which random features we split on\n",
        "  random_features = random.sample(range(0, n_features), nfeat)\n",
        "\n",
        "  for index in random_features:\n",
        "    splitpoint, reduction = bestsplit(x[:, index],y,minleaf)\n",
        "\n",
        "    if reduction > best_reduction:\n",
        "      best_reduction = reduction\n",
        "      best_splitpoint = splitpoint\n",
        "      column_i = index\n",
        "    i+=1\n",
        "  return best_splitpoint, column_i\n",
        "\n",
        "def tree_grow(x, y, nmin, minleaf, nfeat):\n",
        "  observations = len(x)\n",
        "\n",
        "  #the number of observations that a node must contain at least, for it to be\n",
        "  #allowed to be split\n",
        "  #also if the node is already pure, splitting is not needed anymore\n",
        "  if observations < nmin or np.all(y == y[0]): #is np.all(y == 0) correct?\n",
        "    return DecisionNode(value=y, leaf=True)\n",
        "\n",
        "  #find the column that has the best quality of split\n",
        "  splitpoint, feature_index = split(x,y,minleaf,nfeat)\n",
        "\n",
        "  #if the minleaf  constraint is not sasisfied, so if no split can be found that\n",
        "  #creates a node with fewer than minleaf observations is not acceptable.\n",
        "  #leaf node created\n",
        "  if feature_index == None:\n",
        "    return DecisionNode(value=y, leaf=True)\n",
        "\n",
        "  #left\n",
        "  y_l = y[x[:,feature_index]<=splitpoint]\n",
        "  x_l = x[np.where(x[:,feature_index]<=splitpoint)]\n",
        "\n",
        "  #right\n",
        "  y_r = y[x[:,feature_index]>splitpoint]\n",
        "  x_r = x[np.where(x[:,feature_index]>splitpoint)]\n",
        "\n",
        "  #recursion\n",
        "  left_tree = tree_grow(x_l,y_l, nmin, minleaf, nfeat)\n",
        "  right_tree = tree_grow(x_r,y_r, nmin, minleaf, nfeat)\n",
        "\n",
        "  return DecisionNode(feature=feature_index, splitpoint=splitpoint, left=left_tree, right=right_tree, value=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxxoza74lGdL",
        "outputId": "8984d840-f5d8-47e0-c4de-5efdf7e19a24"
      },
      "outputs": [],
      "source": [
        "#data\n",
        "df = pd.read_csv('pima.txt', header=None).to_numpy()\n",
        "\n",
        "x = df[:, 0:8]\n",
        "y = df[:, 8]\n",
        "\n",
        "x_test = df[0:3, 0:8]\n",
        "y_test = df[0, 8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "zNNwpL-fgfVP",
        "outputId": "4392ed88-c59b-4bf9-9ab6-c8b34ff3516b"
      },
      "outputs": [],
      "source": [
        "tr = tree_grow(x,y,10,10,8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "aS7V-7TVf9dN"
      },
      "outputs": [],
      "source": [
        "def tree_pred_one(x, tr):\n",
        "    # returns labels\n",
        "\n",
        "    # if a leaf node is found\n",
        "    if tr.is_leaf_node() == True:\n",
        "        counter = Counter(tr.value)\n",
        "        majority_value = counter.most_common(1)[0][0]\n",
        "        return majority_value\n",
        "    \n",
        "    # otherwise see whether we should go left or right in the decision tree\n",
        "    split_feature = tr.feature\n",
        "    splitpoint = tr.splitpoint\n",
        "\n",
        "    if x[split_feature] > splitpoint:\n",
        "        return tree_pred_one(x,tr.right)\n",
        "    if x[split_feature] <= splitpoint:\n",
        "        return tree_pred_one(x,tr.left)\n",
        "\n",
        "# Tree prediction with just 1 tree, so without bagging\n",
        "def tree_pred(x, tr):\n",
        "    predictions = []\n",
        "    \n",
        "    for datapoint in x:\n",
        "        predictions.append(tree_pred_one(datapoint, tr))\n",
        "    \n",
        "    return np.array(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(tree_pred(x_test,tr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "tN-1cwFvf9dO"
      },
      "outputs": [],
      "source": [
        "# Bagging tree grow, i.e. tree grow with bootstrap aggregating\n",
        "def tree_grow_b(x, y, nmin, minleaf, nfeat, m):\n",
        "    n = x.shape[0]\n",
        "    tree_bags = []\n",
        "    for i in range(m):\n",
        "        index = np.random.choice(n, size=n, replace=True)\n",
        "        new_x = x[index]\n",
        "\n",
        "        tree = tree_grow(new_x,y,nmin,minleaf,nfeat)\n",
        "        tree_bags.append(tree)\n",
        "\n",
        "    return tree_bags # should be a list of trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "Zm0C4Wcuf9dO"
      },
      "outputs": [],
      "source": [
        "# Tree prediction with bagging\n",
        "def tree_pred_b(x, tree_bags):\n",
        "    # for each store what the trees would predict\n",
        "    predictions = []\n",
        "    for tree in tree_bags:\n",
        "        predictions.append(tree_pred(x, tree))\n",
        "\n",
        "    #find the majority prediction\n",
        "    Y = stats.mode(np.array(predictions).T, axis=1, keepdims=False)\n",
        "\n",
        "    return Y.mode.flatten() # Should return a vector y where y[i] contains the predicted class label for row i of x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(tree_pred_b(x_test, tree_grow_b(x, y, 10, 10, 4, 6)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(actual, predicted):\n",
        "    return np.sum(actual == predicted) / len(actual)\n",
        "\n",
        "def precision(actual, predicted):\n",
        "    TP = np.sum((actual == 1) & (predicted == 1))\n",
        "    FP = np.sum((actual == 0) & (predicted == 1))\n",
        "\n",
        "    if (TP + FP) > 0:\n",
        "        return TP / (TP + FP)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def recall(actual, predicted):\n",
        "    TP = np.sum((actual == 1) & (predicted == 1))\n",
        "    FN = np.sum((actual == 1) & (predicted == 0))\n",
        "    \n",
        "    if (TP + FN) > 0:\n",
        "        return TP / (TP + FN)\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TRAINING DATA\n",
        "file_path1 = 'eclipse-metrics-packages-2.0.csv'\n",
        "\n",
        "eclipse2 = pd.read_csv(file_path1, sep=';')\n",
        "features = ['pre','ACD_avg', 'ACD_max', 'ACD_sum', 'FOUT_avg', 'FOUT_max', 'FOUT_sum', 'MLOC_avg', 'MLOC_max', 'MLOC_sum', 'NBD_avg', 'NBD_max', 'NBD_sum', 'NOCU', 'NOF_avg', 'NOF_max', 'NOF_sum', 'NOI_avg', 'NOI_max', 'NOI_sum', 'NOM_avg', 'NOM_max', 'NOM_sum', 'NOT_avg', 'NOT_max', 'NOT_sum', 'NSF_avg', 'NSF_max', 'NSF_sum', 'NSM_avg', 'NSM_max', 'NSM_sum', 'PAR_avg', 'PAR_max', 'PAR_sum', 'TLOC_avg', 'TLOC_max', 'TLOC_sum', 'VG_avg', 'VG_max', 'VG_sum']\n",
        "\n",
        "X_train = eclipse2[features].to_numpy()\n",
        "Y_train = (eclipse2['post'] != 0).astype(int).to_numpy() #make it binary (so zero when zero, and 1 when nonzero)\n",
        "\n",
        "#TEST DATA\n",
        "file_path2 = 'eclipse-metrics-packages-3.0.csv'\n",
        "eclipse3 = pd.read_csv(file_path2, sep=';')\n",
        "X_test = eclipse3[features].to_numpy()\n",
        "Y_test = (eclipse3['post'] != 0).astype(int).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.75642965204236\n",
            "Precision: 0.7585034013605442\n",
            "Recall: 0.7124600638977636\n"
          ]
        }
      ],
      "source": [
        "# 1\n",
        "tr = tree_grow(X_train, Y_train, 15, 5, 41)\n",
        "\n",
        "predictions = tree_pred(X_test,tr)\n",
        "\n",
        "print(f\"Accuracy: {accuracy(Y_test, predictions)}\")\n",
        "print(f\"Precision: {precision(Y_test,predictions)}\")\n",
        "print(f\"Recall: {recall(Y_test,predictions)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5143721633888049\n",
            "Precision: 0.4862068965517241\n",
            "Recall: 0.4504792332268371\n"
          ]
        }
      ],
      "source": [
        "#2\n",
        "tr_b = tree_grow_b(X_train, Y_train, 15, 5, 41, 100)\n",
        "predictions_b = tree_pred_b(X_test,tr_b)\n",
        "\n",
        "print(f\"Accuracy: {accuracy(Y_test, predictions_b)}\")\n",
        "print(f\"Precision: {precision(Y_test,predictions_b)}\")\n",
        "print(f\"Recall: {recall(Y_test,predictions_b)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5098335854765507\n",
            "Precision: 0.4779116465863454\n",
            "Recall: 0.3801916932907348\n"
          ]
        }
      ],
      "source": [
        "#3\n",
        "tr_rf = tree_grow_b(X_train, Y_train, 15, 5, 6, 100)\n",
        "\n",
        "predictions_rf = tree_pred_b(X_test,tr_rf)\n",
        "\n",
        "print(f\"Accuracy: {accuracy(Y_test, predictions_rf)}\")\n",
        "print(f\"Precision: {precision(Y_test,predictions_rf)}\")\n",
        "print(f\"Recall: {recall(Y_test,predictions_rf)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
